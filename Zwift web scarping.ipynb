{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "noticed-writing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"https://www.zwiftpower.com/api3.php?do=analysis_list&zwift_id=\"\n",
    "\n",
    "# top riders JSON is situated here ↓\n",
    "# https://www.zwiftpower.com/cache3/lists/2_standings_.json .\n",
    "# Unomment the lines below to use this list of top ~1000 riders\n",
    "#with urllib.request.urlopen(\"https://www.zwiftpower.com/\"\\\n",
    "#                            \"cache3/lists/2_standings_.json\") as response:\n",
    "#    raw_json_top = response.read()\n",
    "    \n",
    "# all riders JSON is located here ↓\n",
    "# https://www.zwiftpower.com/cache3/global/rider_list.json\n",
    "# A version of the list from 2021-03-17 with most of the JSON attributes\n",
    "# stripped (only inlcuding name, zwift id, ftp and rank) is available in\n",
    "# the github repo and can be used by uncommenting the next lines\n",
    "with open(\"minified_rider_list.json\") as file:\n",
    "    raw_json_top = file.read()\n",
    "\n",
    "json_top_rankings_zp = json.loads(raw_json_top)\n",
    "\n",
    "# We are interested in the the top zwifters personal data (name and ID)\n",
    "top_zwifter = json_top_rankings_zp.get(\"data\")\n",
    "top_zwids, riders = [], []\n",
    "\n",
    "# make lists of zwift_ids and rider names\n",
    "for zwifter in top_zwifter:\n",
    "    \n",
    "    # we only want to check riders with zwiftpower rank less than 500\n",
    "    if int(zwifter.get(\"rank\")[:-3]) < 500:\n",
    "        top_zwids.append(zwifter.get(\"zwid\"))\n",
    "        riders.append(zwifter.get(\"name\"))\n",
    "    \n",
    "zwift_ids, setids, names, dates, titles, device_pm, device_st, \\\n",
    "power300_pm, power300_st, group  = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "progress = 0\n",
    "time_start, time_request = time.time(), 0\n",
    "\n",
    "\n",
    "print(f\"Selected {len(top_zwids)} Zwifters with rank below 500 from\"\\\n",
    "      f\" {len(top_zwifter)} Zwifters total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-terminology",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterate over all riders in top rankings\n",
    "# REMEMBER TO RESET START POSITION! \n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "for zwifter, rider in zip(top_zwids[progress:], riders[progress:]):\n",
    "\n",
    "    # calculate remaining time\n",
    "    time_rem = datetime.timedelta(seconds=((time.time() - time_start) / \\\n",
    "                         ((progress+1) / len(top_zwids))))\n",
    "    # print progress\n",
    "    print(f\"# {progress:4}. ID: {zwifter:8}.\"\\\n",
    "          f\" {progress/len(top_zwids) * 100:5.2f} % finished.\"\\\n",
    "          f\" Request time: {time_request:.2f} s. Est.\"\\\n",
    "          f\" {time_rem} remaining.\")\n",
    "\n",
    "    \n",
    "    progress += 1\n",
    "    \n",
    "    # wait for some seconds – don't flood the server\n",
    "    #time.sleep(0.5)\n",
    "    \n",
    "    time_request_start = time.time()\n",
    "    # request analysis JSON for rider\n",
    "    \n",
    "    request = urllib.request.Request(base_url + str(zwifter))\n",
    "    \n",
    "    # try to open the URL. Skip to next rider if there is an error\n",
    "    try:\n",
    "        response = urllib.request.urlopen(request)\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(e.code)\n",
    "        print(e.read()) \n",
    "        continue\n",
    "    except urllib.error.URLError as e:\n",
    "        print(e.code)\n",
    "        print(e.read())\n",
    "        continue\n",
    "    \n",
    "    analysis_json = response.read()\n",
    "    analysis_json_obj = json.loads(analysis_json)\n",
    "    time_request_end = time.time()\n",
    "    time_request = time_request_end - time_request_start\n",
    "\n",
    "    # get every race for current rider\n",
    "    races = analysis_json_obj.get(\"data\")\n",
    "          \n",
    "    \n",
    "    # iterate over each race\n",
    "    for race in races:\n",
    "        \n",
    "        # if the race has exactly 2 power values for 300s power...\n",
    "        # ... and none of the values are zero\n",
    "        if race.get(\"power300\") and 0 not in race.get(\"power300\"):\n",
    "            num_devices = len(race.get(\"power300\"))\n",
    "        else:\n",
    "            num_devices = 0\n",
    "        if num_devices == 2:\n",
    "            devices = []\n",
    "            \n",
    "            # device names are stored as name1, name2 etc.\n",
    "            for i in range(num_devices):\n",
    "                devices.append(race.get(\"name\" + str(i+1)))\n",
    "            \n",
    "            \n",
    "            if 0 in devices:\n",
    "                continue\n",
    "\n",
    "            \n",
    "            # regex matching kickr but not if bike or snap is included in name\n",
    "            wahoo_search = [i for i in devices if \\\n",
    "                            (re.search(\".*kickr*\", i, re.I) and not \\\n",
    "                             re.search(\".*bike.*|.snap.*\", i, re.I))]\n",
    "            \n",
    "            # if match for kickr and 2 devices and max 10 % difference between\n",
    "            # device power readings, add values to lists.\n",
    "            if wahoo_search and num_devices == 2 and \\\n",
    "                abs(race.get(\"power300\")[0]/race.get(\"power300\")[1] - 1) \\\n",
    "                < 0.1:\n",
    "                wahoo_index = devices.index(wahoo_search[0])\n",
    "                setids.append(race.get(\"set_id\"))\n",
    "                zwift_ids.append(zwifter)\n",
    "                names.append(rider)\n",
    "                dates.append(race.get(\"date\"))\n",
    "                titles.append(race.get(\"title\"))\n",
    "                group.append(\"wahoo\")\n",
    "                if wahoo_index == 1:\n",
    "                    device_pm.append(devices[0])\n",
    "                    device_st.append(devices[1])\n",
    "                    power300_pm.append(race.get(\"power300\")[0])\n",
    "                    power300_st.append(race.get(\"power300\")[1])\n",
    "                else:\n",
    "                    device_pm.append(devices[1])\n",
    "                    device_st.append(devices[0])\n",
    "                    power300_pm.append(race.get(\"power300\")[1])\n",
    "                    power300_st.append(race.get(\"power300\")[0])\n",
    "                                                   \n",
    "            \n",
    "            # regex matching neo but not if 2 comes after neo (except when the)\n",
    "            # 2 is followed by a 0 (as in 20), so that a Tacx Neo 2017 is \n",
    "            # included in the match, but not Tacx Neo 2T\n",
    "            neo_search = [i for i in devices if \\\n",
    "                          (re.search(\".*neo(?![2t])\", i, re.I) and not\\\n",
    "                           re.search(\"2(?!0)\", i, re.I))]\n",
    "            \n",
    "            if neo_search and num_devices == 2 and \\\n",
    "                abs(race.get(\"power300\")[0]/race.get(\"power300\")[1] - 1) \\\n",
    "                < 0.1:\n",
    "                neo_index = devices.index(neo_search[0])\n",
    "                setids.append(race.get(\"set_id\"))\n",
    "                zwift_ids.append(zwifter)\n",
    "                names.append(rider)\n",
    "                dates.append(race.get(\"date\"))\n",
    "                titles.append(race.get(\"title\"))\n",
    "                group.append(\"neo\")\n",
    "                if neo_index == 1:\n",
    "                    device_pm.append(devices[0])\n",
    "                    device_st.append(devices[1])\n",
    "                    power300_pm.append(race.get(\"power300\")[0])\n",
    "                    power300_st.append(race.get(\"power300\")[1])\n",
    "                else:\n",
    "                    device_pm.append(devices[1])\n",
    "                    device_st.append(devices[0])\n",
    "                    power300_pm.append(race.get(\"power300\")[1])\n",
    "                    power300_st.append(race.get(\"power300\")[0])\n",
    "\n",
    "print(f\"Finished! Saved {len(zwift_ids)} rows in {time.time()-time_start} s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "everyday-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mash all of the lists into a much more efficient pandas dataframe structure\n",
    "df = pd.DataFrame({\"zwift_id\": zwift_ids, \"name\": names, \"time\":\\\n",
    "                   pd.to_datetime(dates, unit=\"s\"), \\\n",
    "                   \"group\": group, \"title\": titles, \"pm\": device_pm,\\\n",
    "                   \"st\": device_st, \"p300s_pm\": power300_pm,\\\n",
    "                   \"p300s_st\": power300_st}, index=setids)\n",
    "\n",
    "# drop the duplicate values. no mercy!\n",
    "df = df[~df.duplicated(keep=\"first\")]\n",
    "\n",
    "# calculate the delta (diffrence) between power meter and smart trainer\n",
    "df[\"delta\"] = df[\"p300s_pm\"] - df[\"p300s_st\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "powered-speaker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahoo Kickr statistics:\n",
      "           zwift_id      p300s_pm      p300s_st         delta\n",
      "count  1.601800e+04  16018.000000  16018.000000  16018.000000\n",
      "mean   4.016378e+05    342.000749    340.726995      1.273755\n",
      "std    3.614234e+05     64.777676     64.554816      9.962402\n",
      "min    4.990000e+02     59.000000     57.000000    -41.000000\n",
      "25%    1.038790e+05    304.000000    303.000000     -5.000000\n",
      "50%    2.910990e+05    349.000000    348.000000      1.000000\n",
      "75%    6.066520e+05    386.000000    385.000000      7.000000\n",
      "max    1.531760e+06    529.000000    538.000000     48.000000\n",
      "\n",
      "\n",
      " Tacx Neo statistics:\n",
      "           zwift_id     p300s_pm     p300s_st        delta\n",
      "count  3.053000e+03  3053.000000  3053.000000  3053.000000\n",
      "mean   2.918020e+05   329.387815   326.174910     3.212905\n",
      "std    3.171402e+05    55.982441    55.930461     9.227282\n",
      "min    3.200000e+02   109.000000   112.000000   -35.000000\n",
      "25%    7.031400e+04   297.000000   293.000000    -2.000000\n",
      "50%    1.659770e+05   332.000000   330.000000     3.000000\n",
      "75%    4.154930e+05   366.000000   364.000000     9.000000\n",
      "max    1.478045e+06   501.000000   495.000000    34.000000\n"
     ]
    }
   ],
   "source": [
    "# print key stats (mean + std.dev) for the Kickr and Neo\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "print(f\"Wahoo Kickr statistics:\")\n",
    "print(df.loc[df[\"group\"] == \"wahoo\"].describe())\n",
    "print(f\"\\n\\n Tacx Neo statistics:\")\n",
    "print(df.loc[df[\"group\"] == \"neo\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "behavioral-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv without rider names\n",
    "df.drop(\"name\", axis = 1).to_csv(\"data2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
